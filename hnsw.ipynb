{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hnswlib\n",
      "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.0-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Building wheels for collected packages: hnswlib\n",
      "  Building wheel for hnswlib (pyproject.toml): started\n",
      "  Building wheel for hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp311-cp311-win_amd64.whl size=149905 sha256=f7d07f889c692f831645956894027eeb74ad155ea9d11b0f3d352e414e0eaf86\n",
      "  Stored in directory: c:\\users\\pc\\appdata\\local\\pip\\cache\\wheels\\78\\cf\\dd\\f68cc40d533e8203a7207eb44fbb32cf1243c9fea1962cfa23\n",
      "Successfully built hnswlib\n",
      "Installing collected packages: numpy, hnswlib\n",
      "Successfully installed hnswlib-0.8.0 numpy-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install hnswlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\pc\\downloads\\hnsw benachmark py\\hnsw_env\\lib\\site-packages (2.2.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "     --------------------------------------- 11.1/11.1 MB 16.4 MB/s eta 0:00:00\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.3-cp311-cp311-win_amd64.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 12.8 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 301.8/301.8 kB 6.2 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "     -------------------------------------- 219.8/219.8 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.2-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 56.0/56.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\downloads\\hnsw benachmark py\\hnsw_env\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 10.9 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.9/106.9 kB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc\\downloads\\hnsw benachmark py\\hnsw_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\downloads\\hnsw benachmark py\\hnsw_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: threadpoolctl, scipy, pyparsing, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.2 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.9.3 pillow-11.0.0 pyparsing-3.2.0 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: hnswlib\n",
      "Version: 0.8.0\n",
      "Summary: hnswlib\n",
      "Home-page: https://github.com/yurymalkov/hnsw\n",
      "Author: Yury Malkov and others\n",
      "Author-email: \n",
      "License: \n",
      "Location: C:\\Users\\Pc\\Downloads\\hnsw benachmark py\\hnsw_env\\Lib\\site-packages\n",
      "Requires: numpy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set parameters\n",
    "dim = 128  # Dimension of the vectors\n",
    "\n",
    "num_elements = 10000  # Number of elements to add\n",
    "# Initialize the index\n",
    "p = hnswlib.Index(space='l2', dim=dim)  # 'l2' refers to the Euclidean distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate random data\n",
    "\n",
    "data = np.float32(np.random.random((num_elements, dim)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the number of threads used during the build process\n",
    "\n",
    "p.set_num_threads(4)\n",
    "\n",
    "# Build the index\n",
    "\n",
    "p.init_index(max_elements=num_elements, ef_construction=200, M=16)\n",
    "\n",
    "p.add_items(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the exploration factor (ef)\n",
    "\n",
    "p.set_ef(50)  # ef should always be greater than k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate random queries\n",
    "\n",
    "query_data = np.float32(np.random.random((100, dim)))\n",
    "\n",
    "# Perform the query\n",
    "\n",
    "labels, distances = p.knn_query(query_data, k=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(labels) == 100  # Ensure we get results for all queries\n",
    "\n",
    "assert labels.shape[1] == 10  # Ensure each query returns 10 nearest neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 6.42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare results with brute-force search\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "true_distances = euclidean_distances(query_data, data)\n",
    "\n",
    "true_labels = np.argsort(true_distances, axis=1)[:, :10]\n",
    "\n",
    "# Check if the HNSW results match the brute-force results\n",
    "\n",
    "accuracy = np.mean([np.isin(labels[i], true_labels[i]).sum() for i in range(len(labels))])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query time: 0.031002044677734375 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "p.knn_query(query_data, k=10)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Query time: {end_time - start_time} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ef>k takes more time\n",
    "#with cosine\n",
    "# Yes, in this code the filter function (filter_function(idx)) takes an ID and returns True/False based on whether the point's label matches the target label, by checking self.labels[idx] == target_label.\n",
    "\n",
    "# Data: (N=3000) × (d=16) matrix of uniform random values\n",
    "# Labels: N-length array of categorical values ['a','b','c']\n",
    "# IDs: Array [0 to N-1] matching data indices\n",
    "# Queries: (num_queries=100) × (d=16) matrix of uniform random values\n",
    "\n",
    "# The filtering is categorical, using the 1D label array to filter the d-dimensional data points during search.\n",
    "\n",
    "\n",
    "\n",
    "# recall = |filtered_results ∩ true_results| / |true_results|\n",
    "\n",
    "# Here's a simple example of the data format for N=5 points with d=4 dimensions:\n",
    "# Data matrix (5×4):\n",
    "# pythonCopydata = [\n",
    "#     [0.1, 0.2, 0.3, 0.4],  # point 0\n",
    "#     [0.5, 0.6, 0.7, 0.8],  # point 1\n",
    "#     [0.2, 0.3, 0.4, 0.5],  # point 2\n",
    "#     [0.6, 0.7, 0.8, 0.9],  # point 3\n",
    "#     [0.3, 0.4, 0.5, 0.6]   # point 4\n",
    "# ]\n",
    "# Labels (5×1):\n",
    "# pythonCopylabels = ['a', 'b', 'a', 'c', 'b']\n",
    "# Query example (1×4):\n",
    "# query = [0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "# Yes, the numbers in the data matrix are embeddings - vectors representing the features/characteristics of each point in a d-dimensional space. In this example they're randomly generated but in real applications they would be meaningful embeddings like image features, text embeddings, etc.\n",
    "\n",
    "\n",
    "# In this code, queries don't have labels - they're just feature vectors. The search finds the k nearest data points to each query point, but only among data points that have the specified label in the filter. So if filtering for label 'a', it will return the closest points that have label 'a', ignoring points with other labels\n",
    "\n",
    "\n",
    "# Specificity = (Number of points passing filter) / (Total number of points)\n",
    "# Recall = |Retrieved True Nearest Neighbors ∩ Actual True Nearest Neighbors| / |Actual True Nearest Neighbors|\n",
    "# Latency Overhead = Filtered Query Time / Unfiltered Query Time\n",
    "\n",
    "\n",
    "# ef_construction (higher = better recall, slower build)\n",
    "# ef (higher = better recall, slower search)\n",
    "# M (more connections = better recall, more memory)\n",
    "\n",
    "\n",
    "\n",
    "# Yes, this makes sense:\n",
    "# When 'a' is 33.3% of points:\n",
    "\n",
    "# Filtered latency: 0.20ms\n",
    "# Must search wider to find k neighbors\n",
    "\n",
    "# When 'a' is 60% of points:\n",
    "\n",
    "# Filtered latency: 0.11ms (faster)\n",
    "# Can find k neighbors more quickly since more points qualify\n",
    "\n",
    "# The latency decreased from 0.20ms to 0.11ms when specificity increased from 33.3% to 60% because:\n",
    "\n",
    "# More qualifying points are found earlier in the search\n",
    "# Less \"wasted\" exploration of points that don't match the filter\n",
    "# Can search a smaller radius to find k valid neighbors\n",
    "\n",
    "# So higher specificity = faster search times, which is exactly what we see here\n",
    "\n",
    "\n",
    "# For recall: You can use index.getDataRetrieval() in HNSWLIB to get actual nearest neighbors, \n",
    "\n",
    "\n",
    "\n",
    "# When you do hnsw_index.knn_query(..., filter=filter_function), the filter is checking the data points' IDs, not anything about the queries \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, tunable aspects are satisfied through:\n",
    "\n",
    "# Adjustable EF values (ef_values)\n",
    "# Tunable alpha in power law (skewed_data1)\n",
    "# Tunable cluster_std in correlated data\n",
    "# Adjustable range in range filter\n",
    "# Configurable dim and num_elements in init\n",
    "\n",
    "# All key parameters can be modified to test different scenarios.\n",
    "\n",
    "\n",
    "# Yes, accuracy is measured through recall@k, which compares filtered results against unfiltered (ground truth) results. No need for separate accuracy metric.\n",
    "\n",
    "\n",
    "# Filter friction is measured indirectly through:\n",
    "\n",
    "# Latency differences (filtered vs unfiltered)\n",
    "# Throughput impact\n",
    "# Recall degradation\n",
    "# Specificity percentages\n",
    "\n",
    "# Together these show how the index \"behaves\" under different filter conditions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hnsw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
